{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speaker Gender \\& Age Classification\n",
    "\n",
    "> Copyright 2019 Dave Fernandes. All Rights Reserved.\n",
    "> \n",
    "> Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "> you may not use this file except in compliance with the License.\n",
    "> You may obtain a copy of the License at\n",
    ">\n",
    "> http://www.apache.org/licenses/LICENSE-2.0\n",
    ">  \n",
    "> Unless required by applicable law or agreed to in writing, software\n",
    "> distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "> WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "> See the License for the specific language governing permissions and\n",
    "> limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "CSV_FILE = './Data/speech_means.csv'\n",
    "\n",
    "# Read CSV file from Sonneta and convert categoricals to integers\n",
    "all_data = pd.read_csv(CSV_FILE, index_col=0)\n",
    "all_data = pd.get_dummies(all_data, drop_first=True, columns=['Group', 'Gender'])\n",
    "\n",
    "# Filter\n",
    "all_data = all_data[all_data.Status == 'Normal']\n",
    "\n",
    "# Move features to X and labels to y\n",
    "label_names = ['Age', 'Group_Young', 'Gender_Male', 'Status']\n",
    "X = all_data.drop(label_names, axis=1)\n",
    "y = all_data[label_names]\n",
    "del all_data\n",
    "\n",
    "# Drop unnecessary features and labels\n",
    "y.drop(['Age', 'Status'], axis=1, inplace=True)\n",
    "X.drop(['SFR_dB', 'SD_SFR_dB'], axis=1, inplace=True)\n",
    "\n",
    "#X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "group_label = ['Older', 'Young']\n",
    "gender_label = [' Female', ' Male']\n",
    "labels = []\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        labels.append(group_label[j] + gender_label[i])\n",
    "\n",
    "def evaluate(model, y_actual, y_predicted):\n",
    "    class_predicted = y_predicted[:, 0] + 2*y_predicted[:, 1]\n",
    "    class_actual = y_actual[:, 0] + 2*y_actual[:, 1]\n",
    "    \n",
    "    report = classification_report(class_actual, class_predicted, target_names=labels)\n",
    "    print(report)\n",
    "    \n",
    "    print('Confusion Matrix')\n",
    "    cm = confusion_matrix(class_actual, class_predicted)\n",
    "    cm_norm = 1 / np.sum(cm, axis=1, keepdims=True)\n",
    "    print(np.round(100 * cm * cm_norm) / 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier\n",
    "### Hyper-parameter search\n",
    "Find the top candidate parameter sets for the classifier using a random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "model = RandomForestClassifier(class_weight='balanced')\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"parameters = {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "# Specify parameters and distributions to sample from\n",
    "param_dist = {\"max_depth\": np.append(np.arange(3, X.shape[1] + 1), None),\n",
    "              \"max_features\": sp_randint(1, X.shape[1]),\n",
    "              \"min_samples_split\": sp_randint(2, 6),\n",
    "              \"min_samples_leaf\": sp_randint(1, 5),\n",
    "              \"n_estimators\": sp_randint(5, 50),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# Run randomized search\n",
    "n_iter_search = 1000\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=n_iter_search, cv=5)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X, y)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidate parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation\n",
    "#### Jackknife evaluation\n",
    "Because the sample size is small, we don't want to split the dataset into training and test sets. Instead we do a jackknife evaluation as follows.\n",
    "* Pull out an individual sample (study participant) as the test \\\"set\\\" and train on all remaining samples.\n",
    "* Compare the prediction for this sample versus the actual classification.\n",
    "* Repeat this process using each sample in turn as the test sample.\n",
    "* Tabulate all the \\(predicted class, actual class\\) pairs to generate the confusion matrix. This last step is done 10 times for each holdout sample to average over the randomness in the model training procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIALS = 10\n",
    "parameters = {'criterion': 'entropy', 'max_depth': 6, 'max_features': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 39}\n",
    "\n",
    "y_jack_test = None\n",
    "for X_test, y_test in zip(X.iterrows(), y.iterrows()):\n",
    "    X_train = X.drop(X_test[0], axis=0)\n",
    "    y_train = y.drop(y_test[0], axis=0)\n",
    "    X_test = pd.DataFrame([X_test[1]], [X_test[0]])\n",
    "    y_test = pd.DataFrame([y_test[1]], [y_test[0]])\n",
    "    \n",
    "    # Run several trials for each holdout set to average over the randomness in the model training\n",
    "    for k in range(TRIALS):\n",
    "        model = RandomForestClassifier(**parameters)\n",
    "        model.set_params(class_weight='balanced')\n",
    "        model.fit(X_train, y_train)\n",
    "        y_predicted = model.predict(X_test)\n",
    "\n",
    "        if y_jack_test is None:\n",
    "            y_jack_test = y_test.values\n",
    "            y_jack_pred = y_predicted\n",
    "        else:\n",
    "            y_jack_test = np.concatenate((y_jack_test, y_test.values), axis=0)\n",
    "            y_jack_pred = np.concatenate((y_jack_pred, y_predicted), axis=0)\n",
    "\n",
    "print('Trials:', TRIALS, 'Parameters:', model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate(model, y_jack_test, y_jack_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine feature contribution\n",
    "Determine how important each feature is to the classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Train a model using all the data\n",
    "model = RandomForestClassifier(**parameters)\n",
    "model.set_params(class_weight='balanced')\n",
    "model.fit(X, y)\n",
    "\n",
    "# Plot SHAP values\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X)\n",
    "shap.summary_plot(shap_values, X, class_names=['Age Group', 'Gender'], plot_type='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Impact [Old - Young]')\n",
    "shap.summary_plot(shap_values[0], X, plot_type='layered_violin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Impact [Female - Male]')\n",
    "shap.summary_plot(shap_values[1], X, plot_type='layered_violin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
